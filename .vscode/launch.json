{
    // Use IntelliSense to learn about possible attributes.
    // Hover to view descriptions of existing attributes.
    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387

    //python -m accelerate.commands.launch --num_processes=1 --main_process_port=16849 -m lmms_eval --model slime --model_args pretrained=/data0/jingran/workspace/hongxin_li/highres_autogui/checkpoints/0922_SLIME_Llama3-8B_AutoGUI702k,device_map=auto --tasks func_pred_rec,screenspot_rec,motif,vwb,refexp --batch_size 1 --log_samples --log_samples_suffix test --output_path ./logs/
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Python Debugger: Current File",
            "type": "debugpy",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal",
            "env": {
                "CUDA_VISIBLE_DEVICES": "0",
            },
        },
        {
            "name": "eval-llava_hf",
            "type": "debugpy",
            "request": "launch",
            "module": "accelerate.commands.launch",
            // "program": "",
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--num_processes=1",
                // "--gpu_ids", "0",
                // "--main_process_port=14343",
                "-m", "lmms_eval",
                "--model", "llava_hf", // seeclick, qwen_vl_chat deepseek_vl_chat
                "--model_args", "device_map=auto",
                "--tasks", "func_pred_rec, screenspot_rec, motif, vwb, refexp", // func_pred_rec, screenspot_rec, motif
                "--batch_size", "1",
                "--log_samples",
                "--log_samples_suffix", "test",
                "--output_path", "./logs/",
                // "--limit", "0.005"
                // "--verbosity", "DEBUG"
                ],
                "env": {
                    "CUDA_VISIBLE_DEVICES": "0",
                },
        },
        {
            "name": "eval-seeclick",
            "type": "debugpy",
            "request": "launch",
            "module": "accelerate.commands.launch",
            // "program": "",
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--num_processes=1",
                // "--gpu_ids", "0",
                // "--main_process_port=14343",
                "-m", "lmms_eval",
                "--model", "seeclick", // seeclick, qwen_vl_chat deepseek_vl_chat
                "--model_args", "pretrained=cckevinn/SeeClick",
                "--tasks", "vwb", // func_pred_rec, screenspot_rec, motif
                "--batch_size", "1",
                "--log_samples",
                "--log_samples_suffix", "test",
                "--output_path", "./logs/",
                "--limit", "0.1"
                // "--verbosity", "DEBUG"
                ],
                "env": {
                    "CUDA_VISIBLE_DEVICES": "0",
                },
        },
        {
            "name": "eval-qwen",
            "type": "debugpy",
            "request": "launch",
            "module": "accelerate.commands.launch",
            // "program": "",
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--num_processes=1",
                // "--gpu_ids", "0",
                // "--main_process_port=14343",
                "-m", "lmms_eval",
                "--model", "qwen_vl_chat", // seeclick, qwen_vl_chat deepseek_vl_chat
                "--tasks", "vwb", // func_pred_rec, screenspot_rec, motif, refexp
                "--batch_size", "1",
                "--log_samples",
                "--log_samples_suffix", "test",
                "--output_path", "./logs/",
                // "--limit", "0.01"
                // "--verbosity", "DEBUG"
                ],
                "env": {
                    "CUDA_VISIBLE_DEVICES": "2",
                },
        },
        {
            "name": "eval-autogui",
            "type": "debugpy",
            "request": "launch",
            "module": "accelerate.commands.launch",
            // "program": "",
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--num_processes=1",
                // "--gpu_ids", "0",
                // "--main_process_port=14343",
                "-m", "lmms_eval",
                "--model", "autogui", // seeclick, qwen_vl_chat deepseek_vl_chat
                "--model_args", "pretrained=/data0/jingran/workspace/hongxin_li/seeclick_exp/checkpoints/seeclick_scaling_funcpred625k_llava150k_cauldron197k_refGnd_resample_v2/final",
                "--tasks", "func_pred_rec,screenspot_rec,motif,vwb,refexp", // func_pred_rec,screenspot_rec,motif,vwb,refexp
                "--batch_size", "1",
                "--log_samples",
                "--log_samples_suffix", "test",
                "--output_path", "./logs/",
                //"--limit", "0.01"
                // "--verbosity", "DEBUG"
                ],
                "env": {
                    "CUDA_VISIBLE_DEVICES": "0",
                },
        },
        {
            "name": "eval-monkey",
            "type": "debugpy",
            "request": "launch",
            "module": "accelerate.commands.launch",
            // "program": "",
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--num_processes=1",
                // "--gpu_ids", "0",
                // "--main_process_port=14343",
                "-m", "lmms_eval",
                "--model", "monkey", // seeclick, qwen_vl_chat deepseek_vl_chat
                "--model_args", "pretrained=echo840/Monkey",
                "--tasks", "func_pred_rec, screenspot_rec, motif, vwb, refexp", // func_pred_rec, screenspot_rec, motif, vwb, refexp
                "--batch_size", "1",
                "--log_samples",
                "--log_samples_suffix", "test",
                "--output_path", "./logs/",
                //"--limit", "0.01"
                // "--verbosity", "DEBUG"
                ],
                "env": {
                    "CUDA_VISIBLE_DEVICES": "0",
                },
        },
        {
            "name": "eval-slime",
            "type": "debugpy",
            "request": "launch",
            "module": "accelerate.commands.launch",
            // "program": "",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--num_processes=1",
                // "--gpu_ids", "0",
                "--main_process_port=16849",
                "-m", "lmms_eval",
                "--model", "slime", // seeclick, qwen_vl_chat deepseek_vl_chat, llava_hf
                "--model_args", "pretrained=yifanzhang114--SliME-Llama3-8B,device_map=auto",
                "--tasks", "func_pred_rec", // func_pred_rec, screenspot_rec, motif, vwb, refexp
                "--batch_size", "1",
                "--log_samples",
                "--log_samples_suffix", "test",
                "--output_path", "./logs/",
                "--limit", "0.05"
                // "--verbosity", "DEBUG"
                ],
                // "env": {
                //     "CUDA_VISIBLE_DEVICES": "5",
                // },
        }
    ]
}