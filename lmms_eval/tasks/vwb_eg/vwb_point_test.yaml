group: vwb_eg
dataset_path: HongxinLi/VWB-EG
task: vwb_eg_test
test_split: test
include: _default_template_vwb_yaml
output_type: generate_until
doc_to_visual: !function utils_point.vwb_doc_to_visual
doc_to_text: !function utils_point.vwb_doc_to_text
doc_to_target: !function  utils_point.vwb_doc_to_target
metadata:
  - version: 0.0
model_specific_prompt_kwargs:
  uipro_qwen2_vl:
    format: uipro_qwen2_vl
    post_prompt: |
      Locate the text "{goal_info}" (Output the center coordinates of the target)
  uipro_qwen2_vl_planning:
    format: uipro_qwen2_vl_planning
    post_prompt: |
      Given the UI screenshot and previous actions, please generate the next move necessary to advance towards task completion. The user's task is: Locate the text "{goal_info}". Touch the target element.
      Action history: Step 1. Travel to the user-specified page. Step 2. Swipe to the target element.
      
      Now, first describe the action intent and then directly plan the next action.
  uipro_florence2:
    format: uipro_florence2
    post_prompt: |
      I want to {goal_info}. Please locate the target element I should interact with. (Output the center coordinates of the target)
  uipro_llavaov:
    format: uipro_llavaov
    post_prompt: |
      Where is the "{goal_info}" element? (Output the center coordinates of the target)
  uipro_internvl2:
    format: uipro_internvl2
    post_prompt: |
      Where is the <ref>"{goal_info}"</ref> element? (Output the bounding box coordinates of the target)
  qwen2vl_showui:
    format: qwen2vl_showui
    post_prompt: |
      Based on the screenshot of the page, I give a text description and you give its corresponding location. The coordinate represents a clickable location [x, y] for an element, which is a relative coordinate on the screenshot, scaled from 0 to 1000. {goal_info}
  ferretui:
    format: ferretui
    post_prompt: |
      Provide the bounding boxes of the mentioned objects. {goal_info}
  autogui:
    format: random
  autogui_llava:
    format: autogui_llava
    post_prompt: |
      Locate the text "{goal_info}" (Output the center coordinates of the target)
  autogui_qwen2_vl:
    format: autogui_qwen2_vl
    ex_post_prompt: |
      I want to view the element with text "{goal_info}". Please locate the target element I should interact with. (Output the center coordinates of the target)
    post_prompt: |
      Locate the element according to its detailed functionality description (Output the center coordinates of the target). The element is used to show the text "{goal_info}"
  tinyclick:
    format: tinyclick
    post_prompt: |
      What to do to execute the command? click on {goal_info}
  seeclick:
    format: seeclick
    post_prompt: |
      Given a screenshot, I will describe a specific element; your task is to predict their locations (with point). {goal_info}
  qwen_vl_chat:
    format: qwen_vl_chat
    pre_prompt: |
      Locate the element according to the UI screenshot and instruction, output the localized bounding box.
    post_prompt: |
      Instruction: {goal_info}.
  slime:
    format: qwen_vl_chat
    post_prompt: |
      What are the bounding box coordinates of the element corresponding to the command "{goal_info}" in this UI screenshot?
  cogagent_chat_hf:
    format: cogagent_chat_hf
    pre_prompt: |
      Generate the target element according to the UI screenshot, instruction. Please provide the answer directly (with grounding). 
    post_prompt: |
      Instruction: {goal_info}.
  deepseek_vl_chat:
    format: deepseek_vl_chat
    post_prompt: |
      In this UI screenshot, what is the position of the element corresponding to the command "{goal_info}"? Output the normalized X and Y coordinates, ranging from 0.0 to 1.0. Note that the X-axis runs horizontally from left (0.0) to right (1.0), and the Y-axis runs vertically from top (0.0) to bottom (1.0). Your should carefully view the image before finally predicting the required position in the format [X, Y].
  ferretui:
    format: ferretui
    post_prompt: |
      Where is the "{goal_info}"?
  uground:
    format: uground
    post_prompt: |
      Your task is to help the user identify the precise coordinates (x, y) of a specific area/element/object on the screen based on a description.

      - Your response should aim to point to the center or a representative point within the described area/element/object as accurately as possible.
      - If the description is unclear or ambiguous, infer the most relevant area or element based on its likely context or purpose.
      - Your answer should be a single string (x, y) corresponding to the point of the interest.

      Description: {goal_info}

      Answer:
  osatlas:
    format: osatlas
    post_prompt: |
      In this UI screenshot, what is the position of the element corresponding to the command "{goal_info}" (with bbox)?
  internvl2:
    format: internvl2
    post_prompt: |
      Please provide the bounding box coordinate of the region this sentence describes: <ref>The "{goal_info}" element</ref>
  florence2:
    format: florence2
    post_prompt: |
      Locate the phrases in the caption: {goal_info}
  uground_llava:
    format: uground_llava
    post_prompt: |
      In the screenshot, where are the pixel coordinates (x, y) of the element corresponding to "{goal_info}"?
  osatlas4b:
    format: osatlas4b
    post_prompt: |
      In the screenshot of this web page, please give me the coordinates of the element I want to click on according to my instructions (with point).
      {goal_info}
  showui:
    format: showui
    post_prompt: |
      {goal_info}
  uitars:
    format: uitars
    post_prompt: |
      Output only the coordinate of one point in your response. What element matches the following task: {goal_info}
  aguvis:
    format: aguvis
    post_prompt: |
      Click the "{goal_info}" element.
process_results: !function utils_point.vwb_point_process_results
model_specific_process_kwargs:
  uipro_qwen2_vl:
    scale: 1000
  uipro_qwen2_vl_planning:
    scale: 1000
  uipro_florence2:
    scale: 1000
  uipro_llavaov:
    scale: 1000
  uipro_internvl2:
   scale: 1000
  qwen2vl_showui:
    scale: 1000
  ferretui:
    scale: 1000
  autogui:
    scale: 100
  autogui_qwen2_vl:
    scale: 1000
  autogui_llava:
    scale: 1000
  uipro:
    scale: 100
  qwen_vl_chat:
    scale: 1000
  monkey:
    scale: 1000
  slime:
    scale: 100
  minicpm_v:
    scale: 1000
  tinyclick:
    scale: 1000
  qwen2_vl:
    scale: 1000
  qwen2_vl_cloud:
    scale: 1000
  uground:
    scale: 1000
  osatlas:
    scale: 1000
  internvl2:
    scale: 1000
  florence2:
    scale: 1000
  uground_llava:
    scale: 1000
  osatlas4b:
  uitars:
    scale: 1000
  aguvis:
    scale: 1000
metric_list: # extract the value according to the metric: "key". Thus, the process_results should output the {key1: , key2: ...}
  - metric: vwb_elem-gnd_result
    aggregation: !function utils_point.vwb_gnd_result
    higher_is_better: true
